\section{Heart model validation}
\label{sec:heart model validation}

The purpose of the model is to generate exemplars of a pre-determined set of tachyarrhythmias.
Each arrhythmia must be either a VT or an SVT.
Each arrhythmia episode must be led by an interval of NSR, to allow the ICD algorithms to acquire an NSR template.

The 19 arrhythmias are:
'AF'    'AF-PVC'    'AF-VF'    'AF-VT'    'AF-ashman'    'Aft'    'Aft-VT'    'NSVT'    'PAC'    'PAC-VF'    'PVC'    'SVT'    'SVT-Wenkebach', 'SVT-Wenkebach-PVC'    'SickSinus'    'VF'    'VT'    'VT-PAC'    'VT-retrograde'.
These have been extracted from the annotations that Jackson provided to the database signals.
\todo[inline]{show example of each, and corresponding model parameter values}

Most exemplars should be physiologically valid, i.e. could've been generated by a human heart.
\gap{We haven't quantified `most'}. 
Moreover, there should be some amount of variability between the exemplars of the same arrhythmia.
\gap{We haven't defined or quantified `variability'}.

\gap{The only validation that was done was to show 19 episodes to Sanjay, one of each arrhythmia.
He said they looked OK.}

\subsection{UVA/PADOVA T1DM model}
Briefly, the UVA/PADOVA T1DM model is obtained by: fitting the model's parameters to the data from 204 normal subjects;
scaling the parameters of the 204 synthetic subjects by various clinically obtained quantities to obtain 204 T1DM patients;
fitting a log-normal distribution to the 204 parameters;
sampling from that distribution.

\textbf{Validation}: First, note that \superemph{their synthetic cohort is fixed} - 300 subjects.
So it actually matters `who' they are - they are not interchangeable with some other 300 subjects.

Its main purpose is to assess control algorithms, specifically to give an idea of how this control algorithm might perform in the wild.
For this, they used 2 criteria: first, whether using the model yields similar clinical outcomes as using the real data. 
Second, statistical summaries of certain "key outcomes".
They also included the anecdotal criterion of matching the profiles (but no details on how, seems to be visual).
Their validation criteria from [Visentin, DTT14] are
\begin{enumerate}
	\item Criterion 1: given a real patient's data, they find one of the 300 synthetic ones that best fits the data, where FIT is 1- $\|BG^{meas} - BG^{sml}\|/\|BG^{meas}-mean(BG^{meas})\|$, where $BG^{meas}$ is the measured blood glucose time series and $BG^{sml}$ is the simulated blood glucose time series.
	Given the best fit synthetic patient, determine whether running the experimental protocol (meals and insulin infusions) on the synthetic patient yields the same \emph{clinical outcomes} as running it on the real patient.
	Clinical outcomes are hypo-, eu-, and hyperglycemia. 
	Clinical outcomes are measured by the custom CG-EGA matrix.
	
	\item Criterion 2: after defining key outcomes (like amount of time spent in hyperglycemia), the outcomes are measured on the real cohort and the synthetic cohort.
	Given that they only had 24 real subjects and 100 synthetic ones, it's not clear what meals were given to the remaining 100-24=76 synthetic subjects.
	Anyway, they assumed certain key outcomes were normally distributed and others not. 
	For each key outcome, they reported Mean $\pm$ SD for both real and synthetic cohorts, along with P values, most of which were non-significant for S2013.
	
	\item Criterion 3: compare BG traces of a real patient and best FIT synthetic dude.
\end{enumerate}

\subsection{Validation strategies}
First, assume we have a fixed cohort of synthetic subjects.
The parameters of the cohort \superemph{must be drawn from a joint distribution}. 
\gap{where do we get that dsbn from?}

We can try and reproduce the above process:
\begin{enumerate}
	\item Criterion 1: given a real patient's AAEL EGM signals, find one of the N synthetic ones that best fits the data, according to some fit measure between the 3D EGMs of real and synthetic patient.
	The $(\tau,\varepsilon)$ degree is a reasonable measure.
	
	Given the best fit synthetic patient, determine whether running the ICD on the synthetic patient yields the same \emph{clinical outcomes} as running it on the real patient. 
	Clinical outcomes are defined as VT or SVT or Other determination by the ICD.
	Clinical outcomes are measured. \gap{How? E.g., is some analog of the CG-EGA appropriate?}.
	
	\item Criterion 2: after defining key outcomes (duration of arrhythmia, percentage of time above a certain rate, incidence of a given arrhythmia type in the cohort, number of delivered shocks or ATPs by a given device, \gap{what else?}), the outcomes are measured on the real cohort and the synthetic cohort.
	For each key outcome, report Mean $\pm$ SD for both real and synthetic cohorts, along with P values.
	\gap{How do we determine which variables are normal and which aren't?}
	
	\item Criterion 3: compare BG traces of a real patient and best FIT synthetic dude.
\end{enumerate}